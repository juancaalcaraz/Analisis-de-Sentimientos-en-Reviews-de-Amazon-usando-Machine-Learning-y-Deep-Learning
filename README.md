# An√°lisis de Sentimientos en Rese√±as de Amazon usando Machine Learning y Deep Learning
> ‚ö†Ô∏è Si no puedes visualizar el notebook directamente en GitHub, puedes abrirlo en Google Colab:

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juancaalcaraz/Analisis-de-Sentimientos-en-Reviews-de-Amazon-usando-Machine-Learning-y-Deep-Learning/blob/main/Analisis_de_sentimientos_con_Scikit_learn.ipynb)

---

## üìå Descripci√≥n

Este proyecto aborda la clasificaci√≥n de rese√±as de productos de Amazon en cinco niveles de sentimiento, desde **muy negativo (0)** hasta **muy positivo (4)**. Dado que el conjunto de datos presenta un fuerte desbalance de clases, se implementaron diversas t√©cnicas para mitigar este efecto y mejorar la capacidad de los modelos para predecir correctamente todas las clases, no solo la mayoritaria.

Se comparan modelos de machine learning cl√°sicos con redes neuronales profundas:

- Regresi√≥n Log√≠stica
- Random Forest
- Multilayer Perceptron (MLP)
- Red Neuronal Bidireccional LSTM (BiLSTM)

---

## üéØ Objetivos

- Clasificar rese√±as de texto en cinco niveles de sentimiento.
- Manejar el desbalance de clases mediante t√©cnicas de muestreo y ajustes en la funci√≥n de p√©rdida.
- Comparar modelos tradicionales y redes neuronales para evaluar su desempe√±o y aplicabilidad en contextos reales.

---

## üìö Dataset

El conjunto de datos proviene de rese√±as de Amazon, y contiene aproximadamente 7.000.000 de muestras etiquetadas en cinco clases. La distribuci√≥n de clases es altamente desbalanceada:

| Clase | Descripci√≥n       | Proporci√≥n estimada |
|-------|-------------------|----------------------|
| 0     | Muy negativo      | ~5%                  |
| 1     | Negativo          | ~7%                  |
| 2     | Neutro            | ~10%                 |
| 3     | Positivo          | ~15%                 |
| 4     | Muy positivo      | ~63%                 |

> ‚ö†Ô∏è **Nota:** Este dataset es propiedad de Amazon y se utiliza bajo una licencia de uso acad√©mico/no comercial, tal como fue presentado en el art√≠culo:  
> **Ni, J., Li, J., & McAuley, J. (2019).** *Justifying recommendations using distantly-labeled reviews and fine-grained aspects*. EMNLP.  
> M√°s informaci√≥n: [https://nijianmo.github.io/amazon](https://nijianmo.github.io/amazon)

---

## üß™ Metodolog√≠a

- **Preprocesamiento:** limpieza, tokenizaci√≥n, vectorizaci√≥n (HashingVectorizer, TF-IDF).
- **Manejo del desbalance:** t√©cnicas de rebalanceo (SMOTE, undersampling), y funciones de p√©rdida adaptativas (class weights, focal loss).
- **Modelado:** implementaci√≥n de cuatro modelos con distintas arquitecturas.
- **Evaluaci√≥n:** m√©tricas de *precision*, *recall*, *F1-score*, *accuracy*, matrices de confusi√≥n y curvas de aprendizaje.

---

## üìà Resultados

### üîπ Regresi√≥n Log√≠stica

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.88      | 0.75   | 0.81     | 6734    |
| 1     | 0.27      | 0.38   | 0.32     | 760     |
| 2     | 0.43      | 0.57   | 0.49     | 560     |
| 3     | 0.34      | 0.41   | 0.37     | 1512    |
| 4     | 0.16      | 0.24   | 0.19     | 434     |

- **Accuracy total:** 64%

---

### üîπ MLP (Multilayer Perceptron)

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.78      | 0.90   | 0.84     | 6734    |
| 1     | 0.32      | 0.20   | 0.25     | 760     |
| 2     | 0.55      | 0.40   | 0.46     | 560     |
| 3     | 0.35      | 0.24   | 0.29     | 1512    |
| 4     | 0.21      | 0.18   | 0.20     | 434     |

- **Accuracy total:** 68.5%

---

### üîπ BiLSTM (Red Neuronal LSTM Bidireccional)

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.445     | 0.746  | 0.557    | 1084    |
| 1     | 0.000     | 0.000  | 0.000    | 839     |
| 2     | 0.363     | 0.354  | 0.358    | 1490    |
| 3     | 0.449     | 0.246  | 0.318    | 2996    |
| 4     | 0.840     | 0.932  | 0.884    | 13591   |

- **Accuracy total:** 73.7%
- **F1 macro:** 0.424  
- **F1 ponderado:** 0.705

**Interpretaci√≥n:**  
Aunque el modelo logra una buena precisi√≥n global gracias al excelente desempe√±o en la clase mayoritaria (clase 4), las clases minoritarias siguen teniendo un rendimiento pobre, especialmente la clase 1, que no fue correctamente predicha en ning√∫n caso. Esto refleja que el modelo, a pesar de su complejidad y capacidad para capturar el contexto, **no logra generalizar bien frente a un dataset tan desbalanceado**, incluso con t√©cnicas adicionales aplicadas.

---

## üìä Interpretaci√≥n general

Se observa que todos los modelos tienden a desempe√±arse mejor en la clase mayoritaria (muy positivo), mientras que las clases minoritarias presentan menor precisi√≥n y recall. T√©cnicas como **SMOTE** y la estrategia **jer√°rquica de predicci√≥n en dos etapas** (polaridad general ‚Üí intensidad) fueron implementadas, aunque **no lograron mejoras sostenidas en la distribuci√≥n real** del conjunto de datos.

Estos resultados reflejan las limitaciones de los enfoques supervisados tradicionales frente a datasets altamente desbalanceados y con clases sem√°nticamente difusas.

---

## üñºÔ∏è Visualizaciones
