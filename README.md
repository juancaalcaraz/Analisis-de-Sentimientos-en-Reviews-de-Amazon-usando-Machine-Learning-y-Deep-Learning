# An√°lisis de Sentimientos en Rese√±as de Amazon usando Machine Learning y Deep Learning
> ‚ö†Ô∏è Si no puedes visualizar el notebook directamente en GitHub, puedes abrirlo en Google Colab:

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juancaalcaraz/Analisis-de-Sentimientos-en-Reviews-de-Amazon-usando-Machine-Learning-y-Deep-Learning/blob/main/Analisis_de_sentimientos_con_Scikit_learn.ipynb)

---

## üìå Descripci√≥n

Este proyecto aborda la clasificaci√≥n de rese√±as de productos de Amazon en cinco niveles de sentimiento, desde **muy negativo (0)** hasta **muy positivo (4)**. Dado que el conjunto de datos presenta un fuerte desbalance de clases, se implementaron diversas t√©cnicas para mitigar este efecto y mejorar la capacidad de los modelos para predecir correctamente todas las clases, no solo la mayoritaria.

Se comparan modelos de machine learning cl√°sicos con redes neuronales profundas:

- Regresi√≥n Log√≠stica
- Random Forest
- Multilayer Perceptron (MLP)
- Red Neuronal Bidireccional LSTM (BiLSTM)

---

## üéØ Objetivos

- Clasificar rese√±as de texto en cinco niveles de sentimiento.
- Manejar el desbalance de clases mediante t√©cnicas de muestreo y ajustes en la funci√≥n de p√©rdida.
- Comparar modelos tradicionales y redes neuronales para evaluar su desempe√±o y aplicabilidad en contextos reales.

---

## üìö Dataset

El conjunto de datos proviene de rese√±as de Amazon, y contiene aproximadamente 7.000.000 de muestras etiquetadas en cinco clases. La distribuci√≥n de clases es altamente desbalanceada:

| Clase | Descripci√≥n       | Proporci√≥n estimada |
|-------|-------------------|----------------------|
| 0     | Muy negativo      | ~5%                  |
| 1     | Negativo          | ~7%                  |
| 2     | Neutro            | ~10%                 |
| 3     | Positivo          | ~15%                 |
| 4     | Muy positivo      | ~63%                 |

> ‚ö†Ô∏è **Nota:** Este dataset es propiedad de Amazon y se utiliza bajo una licencia de uso acad√©mico/no comercial, tal como fue presentado en el art√≠culo:  
> **Ni, J., Li, J., & McAuley, J. (2019).** *Justifying recommendations using distantly-labeled reviews and fine-grained aspects*. EMNLP.  
> M√°s informaci√≥n: [https://nijianmo.github.io/amazon](https://nijianmo.github.io/amazon)

---

## üß™ Metodolog√≠a

- **Preprocesamiento:** limpieza, tokenizaci√≥n, vectorizaci√≥n (HashingVectorizer, TF-IDF).
- **Manejo del desbalance:** t√©cnicas de rebalanceo (SMOTE, undersampling), y funciones de p√©rdida adaptativas (class weights, focal loss).
- **Modelado:** implementaci√≥n de cuatro modelos con distintas arquitecturas.
- **Evaluaci√≥n:** m√©tricas de *precision*, *recall*, *F1-score*, *accuracy*, matrices de confusi√≥n y curvas de aprendizaje.

---

## üìà Resultados

### üîπ Regresi√≥n Log√≠stica

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.88      | 0.75   | 0.81     | 6734    |
| 1     | 0.27      | 0.38   | 0.32     | 760     |
| 2     | 0.43      | 0.57   | 0.49     | 560     |
| 3     | 0.34      | 0.41   | 0.37     | 1512    |
| 4     | 0.16      | 0.24   | 0.19     | 434     |

- **Accuracy total:** 64%

---

### üîπ MLP (Multilayer Perceptron)

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.78      | 0.90   | 0.84     | 6734    |
| 1     | 0.32      | 0.20   | 0.25     | 760     |
| 2     | 0.55      | 0.40   | 0.46     | 560     |
| 3     | 0.35      | 0.24   | 0.29     | 1512    |
| 4     | 0.21      | 0.18   | 0.20     | 434     |

- **Accuracy total:** 68.5%

---

### üîπ BiLSTM (Red Neuronal LSTM Bidireccional)

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.445     | 0.746  | 0.557    | 1084    |
| 1     | 0.000     | 0.000  | 0.000    | 839     |
| 2     | 0.363     | 0.354  | 0.358    | 1490    |
| 3     | 0.449     | 0.246  | 0.318    | 2996    |
| 4     | 0.840     | 0.932  | 0.884    | 13591   |

- **Accuracy total:** 73.7%
- **F1 macro:** 0.424  
- **F1 ponderado:** 0.705

**Interpretaci√≥n:**  
Aunque el modelo logra una buena precisi√≥n global gracias al excelente desempe√±o en la clase mayoritaria (clase 4), las clases minoritarias siguen teniendo un rendimiento pobre, especialmente la clase 1, que no fue correctamente predicha en ning√∫n caso. Esto refleja que el modelo, a pesar de su complejidad y capacidad para capturar el contexto, **no logra generalizar bien frente a un dataset tan desbalanceado**, incluso con t√©cnicas adicionales aplicadas.

---

## üìä Interpretaci√≥n general

Se observa que todos los modelos tienden a desempe√±arse mejor en la clase mayoritaria (muy positivo), mientras que las clases minoritarias presentan menor precisi√≥n y recall. T√©cnicas como **SMOTE** y la estrategia **jer√°rquica de predicci√≥n en dos etapas** (polaridad general ‚Üí intensidad) fueron implementadas, aunque **no lograron mejoras sostenidas en la distribuci√≥n real** del conjunto de datos.

Estos resultados reflejan las limitaciones de los enfoques supervisados tradicionales frente a datasets altamente desbalanceados y con clases sem√°nticamente difusas.

---

## üñºÔ∏è Visualizaciones
### Desbalanceo de clases:
Esta es la distribuci√≥n de las clases en el dataset:

![Desbalance de clases](img/Desbalance.png)

Como se puede observar en el gr√°fico, la clase **excelente** est√° sobrerrepresentada, representando m√°s del 60% del total del dataset.

---

### Reporte de `SGDClassifier`:
En el primer entrenamiento se utiliz√≥ **SGDClassifier** con `loss='log'` y el vectorizador **HashingVectorizer**.

![SGDClassifier reporte](img/SGDC_reporte.png)

Como se puede ver, las clases **excelente** y **p√©sima** son las que obtienen mejores resultados.

---

### Regresi√≥n log√≠stica:
La regresi√≥n log√≠stica fue otro modelo probado para la clasificaci√≥n. A continuaci√≥n se muestra su resultado con la distribuci√≥n original de los datos:

![Matriz_confusion_LR](img/Matriz_confusion_LR.png)

Aqu√≠ se muestra el resultado al entrenar el modelo con datos balanceados manualmente y evaluarlo con la distribuci√≥n original:

![Matriz_confusion_LR_balanceado](img/Matriz_LR_balanceado_test_desbalanceado.png)

---

Tambi√©n probamos dividir el problema en dos etapas:  
1. Determinar primero la **polaridad general** de la rese√±a.  
2. Luego clasificarla de forma m√°s espec√≠fica con otro modelo entrenado para identificar el **nivel de sentimiento**.

**Matriz de polaridad:**

![Matriz_polaridad](img/Matriz_polaridad.png)

**Matriz del umbral positivo con umbral de decisi√≥n:**

![Matriz_pos_umbral](img/Matriz_pos_umbral.png)

---

### Curva de p√©rdida - MLP:
Otro clasificador que probamos fue el **Multilayer Perceptron (MLP)**.

![MLP curva de p√©rdida](img/Curva_loss_MLP.png)

Como se puede observar, la p√©rdida va disminuyendo a lo largo de las √©pocas de entrenamiento, lo que indica un buen ajuste a los datos de entrenamiento.

---

### Bidirectional LSTM:
Esta es la curva de p√©rdida del entrenamiento y la validaci√≥n del **Bidirectional LSTM**:

![LSTM curva de p√©rdida](img/Curva_de_perdida_Bidirectional_LSTM.png)

Se puede ver c√≥mo la p√©rdida de entrenamiento disminuye con las √©pocas. Sin embargo, la p√©rdida de validaci√≥n no var√≠a demasiado a partir de la **√©poca 4**, lo que indica que el modelo deja de capturar nuevos patrones a partir de ese punto.

---

**Matriz de confusi√≥n de Bidirectional LSTM:**

![Matriz de confusi√≥n](img/Matriz_confusion_Biderectional.png)

A partir de esta matriz podemos inferir que el modelo clasifica adecuadamente los extremos de los polos del sentimiento, as√≠ como el centro. Esto sugiere que, si la clasificaci√≥n se redujera a solo tres clases (por ejemplo: negativa, neutra y positiva), nuestro **Bidirectional LSTM** podr√≠a tener un desempe√±o significativamente mejor que el actual.
 